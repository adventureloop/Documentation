\section{Modern Graphics}
Dedicated hardware has been used for the creation of computer output since the
move away from blinking lights to indicate machine state. Graphics hardware has
been at the fore front of pushing computer power since the first 3D graphics 
cards started to appear in the early 90s and today graphics hardware still push
the limit of hardware even down into the mobile space.\\

Dedicated graphics hardware has allowed for a move from using the CPU of a 
computer to handle complex geometry tasks and as this has happened game designers
and developers have asked for more and more from the graphics chip set
manufacturers. The latest graphics cards are now more generalised vector 
processors that can be applied to many different data calculation intensive tasks
including the creation of complex, interesting and realistic 3D graphics.\\

\subsection{OpenGL Overview} 
Access to the underlying graphics hardware is mitigated through the use of libraries
.These 
libraries have grown up with the graphics cards and together have pushed the 
limits of the hardware. Two competing standards have developed over time, Direct
3D from Microsoft and the OpenGL specification for the ARB group. Direct 3D is 
limited to run only on Microsoft platforms such as window and the xbox console,
but OpenGL is a standard that can be and is implemented everywhere. Due to this
Direct 3D has been discounted as an option for this project and instead OpenGL
has been investigated.\\

OpenGL is a specification for how graphics systems should operate, but also 
defines a software interface that should be implemented to control the operation
of the graphics hardware. As a specification a lot of the under lying 
implementation of the graphics system is left to the manufacturer, instead 
OpenGL defines the outputs that should appear from given inputs to the system,
the rest is a black box.\\

OpenGL's functionality is based around a state machine, this machine needs to be
configured by the programmer for each drawing call, but will preserve this state 
unless otherwise changed. For drawing OpenGL is a very powerful rasteriser, its
main operation being the processing of triangles in the form of vertexes into
pixels on a final display. \\

OpenGL is a description of the interface with the hardware, for 
practical use the operating system must provide the window in which the final
display will appear. This allows the OpenGL commands to be platform agnostic, 
letting windowing functionality come from the OS itself.\\

\subsubsection*{Drawing}
A computer screen is a grid of squares called pixels(picture elements), each
pixel contains red, green and blue components and these are combined to create a 
colour in each pixel. \\

A vector graphic is an image that is made up from mathematical formulae describing
the lines and colours in the image instead of just the colour that should go into the
pixel. Vector graphics
will scale infinitely, you wont see any 
artifacts or large pixels when you zoom. Vector graphics are also easy to define
and very low on memory for simple shapes. 
Rasterisation is the process of converting a vector 
graphic image into the pixels that will be displayed on the screen. 
Graphics cards are 
pieces of hardware called raterisers and are specifically designed to stream line
this process of moving from a vector description of an image to final pixel 
values on the screen.\\

To build up realistic models using vector art graphics systems rely on a large
amount of fakery. OpenGL uses the triangle as its most primitive shape, these
are then combined to create very complex shapes in what are called 
meshes. Any complex shape can be made from a number of triangles, the greater the
desired precision the more triangles are required.\\

\subsection{Rendering Pipeline}
\subsubsection{Triangles and Vertexes}
OpenGL is an interface to the hardware rasteriser, A Vertex is the most 
primitive type that OpenGL can operate with. Each Vertex will describe its 
position in space and may include meta data about itself, like colour 
information. OpenGL has a number of different ways it can use vertex data, but 
the most common is to take vertexes three at a time and use them to create 
triangles.\\

Once the vertex data for all the triangles in a mesh have been passed to OpenGL,
the information will be processed through the rasterisation pipeline. This 
pipeline has several discrete stages, each of which transforms the vertex data 
in some way until the final stage is reached and a colour can be decided for the
pixels in the window.\\

The rough stages for the rasterisation pipeline are:
\begin{description}
\item[Clip Space Transformation] The first phase of the rasterisation process
is transformation of vertexes into clip space. Clip space defines a region in 
space, anything inside of which will be rendered, anything outside of this space
will be discarded. Objects that lie across this boundary will have their surface
broken down into small triangles until all of which lie within clip space, hence
clipping. Positions in clip space have an additional W position, this defines the
extent of clip space for the coordinate in the [-W,W] range.
The operations in clip space can be quite arbitrary as the programmer 
has a lot of control over how the clip transformation operates.

\item[Normalised Device Coordinates] The Normalised Device Coordinate space is 
used to make visualising triangles much simpler. It is effectively the same as 
Clip space, but each coordinated lies within the [-1,1] range. The division is 
part of the projection from 3D shapes to 2D colours.
\item[Window Transformation] Window coordinated are converted to from normalised
device coordinates. In this space each coordinate is relative to the window that
we are rendering into, these coordinates are still 3D and have float point 
precision, window coordinates are not pixel mappings.
\item[Scan Conversion] Scan Conversion takes each triangle as described in 
window coordinated and maps it to pixels that are covered by its shape. Scan 
conversion will create a \emph{fragment} for each pixel sample that is within
the triangles shape.
\item[Fragment Processing] Fragment processing is the phase where each fragment 
is given one of more colours and has as depth value applied against it. This 
phase can also be quote arbitrary as the programmer is given access to the pipeline
as this stage.
\item[Fragment Writing] The phase of the rasterisation pipeline is to write the 
coloured fragment to the display.
\end{description}

\subsection{Shaders}
There are two points in the rasterisation pipeline that have hooks allowing
customisation by the programmer. The first is during Clip Space transformation
and the second is during Fragment Processing. To access the rasteriation pipeline
small programs called shaders are used, these programs have access to the
vertex data in the case of vertex shaders and access to the fragments created in
the case of the fragment shader.\\

OpenGL provides a simple C like language called GLSL(Graphics Library Shading 
Language), GLSL contains extensions that make writing programs that use vectors
and matrices very easy. Built in variables are also provided to allow easier
implementation of shader programs. \\

\lstset{caption={Vertex Shader}}
\lstinputlisting{src/example.vsh}

Inside the vertex shader variables called attributes can be defined that directly
link to the vertex data provided by OpenGL. These variables are declared by 
placing the attribute specifier before the variable in the global block.
Uniforms are variables that can be passed to the shader programs, 
these values are the 
same for each rendering call, but can be changed between render calls. Uniform
variables are used to pass values that would be expensive to calculated with every
call, instead they can be calculated once on the CPU then passed as a variable to
improve speed. Varying variables can be used to pass data between the two shader 
stages, in our example here the outColor variable is used to pass the colour from the
vertex array to the fragment shader.\\

Vertex shaders are used from geometric placement of vertexes and similar tasks
that would involve a lot of processing on the CPU. These are be highly 
parrallelised on the GPU allows for more complex placement than was previously
possible. The vertex shader is also responsible for transforming vertexes into
a view frustum, the visible view area. The vertex shader with also control 
modelling and camera transformations and can be used in simple vertex based forms
of lighting.\\

The fragment shader is much more limited in its scope, it only has access to the
final fragments before they are written,varying variables from the stages before and
any user specified uniforms. Despite
this the fragment shader is responsible for high resolution effects like fog and
many realistic forms of lighting rely on the precision that is only available
within the fragment shader\\

\lstinputlisting{src/example.fsh}

There are many different types of graphics chip sets in the wild and it would be
difficult to create binaries that will run on every graphics card. To get around
this the compilation and linking of shader programs are performed at run time.
This allows our shader programs to run on almost any platform without many
changes.\\ 

\subsection{Programing with OpenGL}
OpenGL is a C API for accessing the functionality of the graphics processor and
updating values in the state machine. Every component of the OpenGL library is
prefixed with GL (GLshort,glColor3f,GL\_DEPTH\_BUFFER\_BIT). 
The library functions for OpenGL are layed out in a very simple manner and it
follows the approach of sane defaults, anytime a context could be needed there 
will be a global one available by default.\\

For rendering each object in OpenGL lives within a context called a Vertex Array
Object(VAO). This context managers object level state within the OpenGL machine, the
state specifies where the render data for the object is mapped in memory, how to 
access that data and any changed to state machine variables.\\

\begin{center}
\includegraphics[width=5cm]{Images/VertexArrays.png}
\end{center}

The vertex data for each object rendered has to be passed to OpenGL inside an array,
this is usually called the vertex array. The vertex array needs to contain the data
that describes the position of the vertex in real terms, it can also contain colour
information and normal data (normal are vectors that describe the direction a face
points).\\

OpenGL provides functions to specify where the vertex data is stored, it is possible
to have the vertex data for positions, colours and normals in different memory arrays
in the computer, but it is much more practical to use interleaved vertex arrays.
Inteleaved vertex arrays have the data for each vertex packed together, so the 
position data is first in the array, then  the colour data, then the normal data. 
This way it is possible to create C structs that describe this layout and then map
those structs onto an array to hold all of the vertex data for the object.\\

\begin{description}
\item[Vertex Array Object] The VAO is the container in which all of the configuration
state for the object is stored.
\item[Vertex Buffer Object]
To provide data to OpenGL a Vertex Buffer Object needs to be created
and assigned to the VAO, the VBO stores where in system memory the vertex data 
is. 
\item[Attribute Binding]
Once the VBO is aligned the program needs to bind the attributes it is going
to provide to the shader program, these are specified by an index given by their
order of definition inside the shader program.
\item[Attribute Pointer Assignment]
Finally the access types of the 
vertex data need to be configured, this is done by setting the attribute 
pointer. 
\end{description}

%OpenGL is only able to operate within a context provided by the operating system
%this configuration is abstracted away in our example, so is the creation of the
%shader programs as these are trivial task, full examples can be seen within the
%resource manager class in the main project. This example should give a precise
%overview of the management functions that OpenGL has to do in order to create a 
%proper context for rendering.\\

%\lstinputlisting{src/progamablepipelineexample.c}
