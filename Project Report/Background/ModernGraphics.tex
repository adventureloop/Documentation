\section{Modern Graphics}
Discrete graphics hardware has existed since the move from printed output to 
teletyped displays. There has been a long history of development in hardware and
for a long time evey increasing graphics speeds led the entire tech industry.\\

\subsection{OpenGL Overview} 
Opengl is a software interface to graphics hardware, it is defined as a hardware
independant specification and is implemented by all major hardware vendors.
Using opengl allows a platform independant and consistent access to acelerated 
graphics functions and is packaged with almost every os produced today.\\

OpenGL implements a state machine which is update via function calls in a user
program. OpenGL's statefulness allows much less complicated drawing models and
effient programming. \\

Opengl does not provide any facility to interact with windows, the keyboard or a 
mouse, instead this needs to be provided by the host OS. All opengl requires is 
a context created by the OS and opengl rendering calls can be used, with a few 
exceptions these calls are the same across all platforms.\\

\subsubsection*{Drawing}
An image on a screen or in a printed document is built up from a grid of picture
elements (pixels). The purpose of a graphics system of any kind is to define the
final colour that ends up in these pixels. A simple 2d image is a direct mapping
to the final screen colour, but a complex 3d scene will go through a number of 
filters before its final colour can be decided. \\

Graphics systems rely on a large amount of fakery to produce realistic final 
scenes, every object defined is made up of a series of triangles. Spheres and
balls are created this way and images are mapped onto these triangles. Graphics
hardware uses a process call rasterisation to transition from these triangle 
definitions to the final pixels on the screen.\\

\subsection{Rendering Pipeline}
The \emph{Vertex} is the basic unit for definition in OpenGL, verticies are used
to define triangle meshes or geometries. A vertex is a point in 3D space, but it
can also have other properities defined for it such as colour or surface normal.
OpenGL uses a rendering pipeline, taking each vertex in turn and processing it 
until a final pixel colour can be defined. \\

\begin{description}
\item[Clip Space Transfromation] The first phase of the rasterisation process
is transformation of vertices into clip space. Clip space defines a region in 
space, anything inside of which will be rendered, anything outside of this space
will be disguared. Objects that lie across this boundary will have their surface
broken down into small triangles until all of which lie within clip space, hence
clipping. Positions in clip space have an additional W position, this defines the
extent of clip space for the coordinate in the [-W,W] range.
The operations in clip space can be quite arbitary as the programmer 
has a lot of control over how the clip transformation operates.

\item[Normalised Device Coordinates] The Normalised Device Coordinate space is 
used to make visualising triangles much simplier. It is effectivly the same as 
Clip space, but each coordinated lies within the [-1,1] range. The division is 
part of the projection from 3D shapes to 2D colours.
\item[Window Transformation] Window coordinated are converted to from normalised
device coordinates. In this space each coordinate is relative to the window that
we are rendering into, these coorinates are still 3D and have float point 
precision, window coordinates are not pixel mappings.
\item[Scan Converstion] Scan Conversion takes each triangle as described in 
window coordinated and maps it to pixels that are covered by its shape. Scan 
conversion will create a \emph{fragment} for each pixel sample that is within
the triangles shape.
\item[Fragment Processing] Fragment processing is the phase where each fragment 
is given one of more colours and has as depth value applied agasint it. This 
phase can also be qute arbitary as the programmer is given access to the pipeline
as this stage.
\item[Fragment Writing] The phase of the rasterisation pipeline is to write the 
coloured fragment to the display.
\end{description}

\subsection{Shaders}
Shaders are programs that are designed to run within the rendering pipeline, they
are small programs that hook into the the pipeline and allow custom algoritms to
create arbitary effects. Shader programs in OpenGL are executed on the GPU 
freeing up CPU processing and the positions they can hook are designed for the
greatest utility for the programmer. Shaders allow for programs that would be 
impossibly intesive on a CPU system, but suffer limitations that would not be 
present in such a system.
OpenGl opens up two stages of the rendering
pipeline to user specified shaders, the transformation of a vertex into clip 
space with a \emph{Vertex Shader} and the processing of fragment into a final
colour in a \emph{Fragment Shader}.\\

There are a number of ways to write programs for these stages in the rendering
pipeline, OpenGL provides the Graphics Library Shading Language(GLSL). GLSL is 
a C like language with extensions for interacting with the vectorised graphics
hardware. Shader programs also have access to builtin variables for output and
input, and user defined variables covering all types of vertex input along with
programmer defined variables. Graphics processors are highly vectorised and GLSL
has builtin vector and matrix types to simplify writing programs.\\

GLSL programs follow the C style program model, but vertex and fragment shaders 
run around a main function with the possiblity to define further functions. The 
following two programs illustrate the general syntax of vertex and fragment 
shaders.\\

\lstinputlisting{src/example.vsh}

\lstinputlisting{src/example.fsh}

Shader programs are compiled and linked at run time, this allows shaders to be 
portable across all types of graphics cards.\\

\subsection{Programing with OpenGL}
OpenGL is a C based API which uses C function calls to access functionality on 
the graphics processor. The API is implemented as a collection of \#define'd 
constants, types and methods, all prefixed with GL 
(GLShort,GL\_DEPTH\_BUFFER\_BIT,glColor3f). OpenGL owns storage for all objects
used in the rendering, user programs have to request access to buffers and offer
memory regions to be used. Due to OpenGL's stateful nature contexts can be used 
in programs to make segmenting up drawing easier, an entity can configure it's 
drawing space, then save this in a context, stopping interferance from other 
entities drawing. \\

OpenGL is a simple API to a very complex underlying state machine, the API is 
very tolerant and provides a lot of the configuration for a global context by 
default. More complex programs need to do more work setting up, but allow the
programmer to create very powerful compartmentalised code that can be reused in 
many situations.\\

Before any drawing can be done, an OpenGL context has to be received from the OS
and the program needs to go through the process of loading and compiling the 
shader programs. For our example these are both abstracted away into functions as
they can be very OS dependant.  \\

\begin{description}
\item[Vertex Array Object] The first OpenGL based configurations is the 
creation of the buffer context and the allocation of memory on the graphics card
to be used. A vertex array object is used to store the locations of attributes 
and drawing related state, the location of the array data is also stored with
this object.
\item[Vertex Buffer Object]
To provide data to OpenGL a Vertex Buffer Object needs to be created
and assigned to the VAO, the VBO stores where in system memory the vertex data 
is. 
\item[Attribute Binding]
Once the VBO is aligned the program needs to bind the attributes it is going
to provide to the shader program, these are specified by an index given by their
order of definition inside the shader program.
\item[Attribute Pointer Assignment]
Finally the access types of the 
vertex data need to be configured, this is done by setting the attribute 
pointer. 
\end{description}

\begin{center}
\includegraphics[width=5cm]{Images/VertexArrays.png}
\end{center}

Vertex data can be packed as an individual array, or stored in an interwieved 
vertex array. This way all of the meta data about the vertex is stored in line 
relative to the vertex itself. This method allows a reduction in the number of 
memory buffers and simplifies specification of information. The 
glVertexAttribPointer function call makes this easy by providing a step value and
an initial offset value for memory locations. These are passed in the final two
parameters to the function call respectivly.\\

\lstinputlisting{src/progamablepipelineexample.c}

